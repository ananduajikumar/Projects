{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression ,LogisticRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC , SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import r2_score, mean_absolute_error , mean_squared_error\n",
    "import os\n",
    "\n",
    "import joblib as jb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Gender ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  \\\n",
       "0   40      M           ATA        140          289          0     Normal   \n",
       "1   49      F           NAP        160          180          0     Normal   \n",
       "2   37      M           ATA        130          283          0         ST   \n",
       "3   48      F           ASY        138          214          0     Normal   \n",
       "4   54      M           NAP        150          195          0     Normal   \n",
       "\n",
       "   MaxHR ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0    172              N      0.0       Up             0  \n",
       "1    156              N      1.0     Flat             1  \n",
       "2     98              N      0.0       Up             0  \n",
       "3    108              Y      1.5     Flat             1  \n",
       "4    122              N      0.0       Up             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('heart_new.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>TA</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>132</td>\n",
       "      <td>N</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>68</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>141</td>\n",
       "      <td>N</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>115</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>LVH</td>\n",
       "      <td>174</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>38</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>173</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Gender ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  \\\n",
       "913   45      M            TA        110          264          0     Normal   \n",
       "914   68      M           ASY        144          193          1     Normal   \n",
       "915   57      M           ASY        130          131          0     Normal   \n",
       "916   57      F           ATA        130          236          0        LVH   \n",
       "917   38      M           NAP        138          175          0     Normal   \n",
       "\n",
       "     MaxHR ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "913    132              N      1.2     Flat             1  \n",
       "914    141              N      3.4     Flat             1  \n",
       "915    115              Y      1.2     Flat             1  \n",
       "916    174              N      0.0     Flat             1  \n",
       "917    173              N      0.0       Up             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               0\n",
       "Gender            0\n",
       "ChestPainType     0\n",
       "RestingBP         0\n",
       "Cholesterol       0\n",
       "FastingBS         0\n",
       "RestingECG        0\n",
       "MaxHR             0\n",
       "ExerciseAngina    0\n",
       "Oldpeak           0\n",
       "ST_Slope          0\n",
       "HeartDisease      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             918 non-null    int64  \n",
      " 1   Gender          918 non-null    object \n",
      " 2   ChestPainType   918 non-null    object \n",
      " 3   RestingBP       918 non-null    int64  \n",
      " 4   Cholesterol     918 non-null    int64  \n",
      " 5   FastingBS       918 non-null    int64  \n",
      " 6   RestingECG      918 non-null    object \n",
      " 7   MaxHR           918 non-null    int64  \n",
      " 8   ExerciseAngina  918 non-null    object \n",
      " 9   Oldpeak         918 non-null    float64\n",
      " 10  ST_Slope        918 non-null    object \n",
      " 11  HeartDisease    918 non-null    int64  \n",
      "dtypes: float64(1), int64(6), object(5)\n",
      "memory usage: 86.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = {}\n",
    "def find_category_mappings(df, variable):\n",
    "    return {k: i for i, k in enumerate(df[variable].unique())}\n",
    "\n",
    "def integer_encode(df, variable, ordinal_mapping):\n",
    "    df[variable] =  df[variable].map(ordinal_mapping)\n",
    "    maps[variable] = mappings\n",
    "    \n",
    "for variable in df.columns:\n",
    "    if df[variable].dtype == \"object\":\n",
    "        mappings = find_category_mappings(df, variable)\n",
    "        integer_encode(df, variable,  mappings)\n",
    "        maps[variable] = mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gender': {'M': 0, 'F': 1},\n",
       " 'ChestPainType': {'ATA': 0, 'NAP': 1, 'ASY': 2, 'TA': 3},\n",
       " 'RestingECG': {'Normal': 0, 'ST': 1, 'LVH': 2},\n",
       " 'ExerciseAngina': {'N': 0, 'Y': 1},\n",
       " 'ST_Slope': {'Up': 0, 'Flat': 1, 'Down': 2}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"map.txt\", \"w\") as file:\n",
    "    file.write(str(maps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
       "0   40       0              0        140          289          0           0   \n",
       "1   49       1              1        160          180          0           0   \n",
       "2   37       0              0        130          283          0           1   \n",
       "3   48       1              2        138          214          0           0   \n",
       "4   54       0              1        150          195          0           0   \n",
       "\n",
       "   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  \n",
       "0    172               0      0.0         0  \n",
       "1    156               0      1.0         1  \n",
       "2     98               0      0.0         0  \n",
       "3    108               1      1.5         1  \n",
       "4    122               0      0.0         0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>114</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender  ChestPainType  RestingBP  Cholesterol  FastingBS  \\\n",
       "898   35       0              0        122          192          0   \n",
       "899   61       0              2        148          203          0   \n",
       "900   58       0              2        114          318          0   \n",
       "901   58       1              2        170          225          1   \n",
       "902   58       0              0        125          220          0   \n",
       "903   56       0              0        130          221          0   \n",
       "904   56       0              0        120          240          0   \n",
       "905   67       0              1        152          212          0   \n",
       "906   55       1              0        132          342          0   \n",
       "907   44       0              2        120          169          0   \n",
       "908   63       0              2        140          187          0   \n",
       "909   63       1              2        124          197          0   \n",
       "910   41       0              0        120          157          0   \n",
       "911   59       0              2        164          176          1   \n",
       "912   57       1              2        140          241          0   \n",
       "913   45       0              3        110          264          0   \n",
       "914   68       0              2        144          193          1   \n",
       "915   57       0              2        130          131          0   \n",
       "916   57       1              0        130          236          0   \n",
       "917   38       0              1        138          175          0   \n",
       "\n",
       "     RestingECG  MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
       "898           0    174               0      0.0         0             0  \n",
       "899           0    161               0      0.0         0             1  \n",
       "900           1    140               0      4.4         2             1  \n",
       "901           2    146               1      2.8         1             1  \n",
       "902           0    144               0      0.4         1             0  \n",
       "903           2    163               0      0.0         0             0  \n",
       "904           0    169               0      0.0         2             0  \n",
       "905           2    150               0      0.8         1             1  \n",
       "906           0    166               0      1.2         0             0  \n",
       "907           0    144               1      2.8         2             1  \n",
       "908           2    144               1      4.0         0             1  \n",
       "909           0    136               1      0.0         1             1  \n",
       "910           0    182               0      0.0         0             0  \n",
       "911           2     90               0      1.0         1             1  \n",
       "912           0    123               1      0.2         1             1  \n",
       "913           0    132               0      1.2         1             1  \n",
       "914           0    141               0      3.4         1             1  \n",
       "915           0    115               1      1.2         1             1  \n",
       "916           2    174               0      0.0         1             1  \n",
       "917           0    173               0      0.0         0             0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=x.values()\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "Name: HeartDisease, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  cutting out test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[2:3].to_csv('heart1.csv')\n",
    "# df.iloc[3:4].to_csv('heart2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
       "3   48       1              2        138          214          0           0   \n",
       "\n",
       "   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  \n",
       "3    108               1      1.5         1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3 = x.iloc[3:4]\n",
    "r3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  rows with label 1 ----> 3,500,115,900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1\n",
       "Name: HeartDisease, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3 = y.iloc[3:4]\n",
    "l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500    1\n",
       "Name: HeartDisease, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l500 = y.iloc[500:501]\n",
    "l500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115    1\n",
       "Name: HeartDisease, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l115 = y.iloc[115:116]\n",
    "l115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900    1\n",
       "Name: HeartDisease, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l900 = y.iloc[900 :901]\n",
    "l900 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  rows with label 0 ----> 600 , 800 , 80 , 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600    0\n",
       "Name: HeartDisease, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l600 = y.iloc[600:601]\n",
    "l600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800    0\n",
       "Name: HeartDisease, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l800 = y.iloc[800:801]\n",
    "l800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80    0\n",
       "Name: HeartDisease, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l80 = y.iloc[80:81]\n",
    "l80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55    0\n",
       "Name: HeartDisease, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l55 = y.iloc[55:56]\n",
    "l55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  save to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.iloc[3:4].to_csv('test3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.iloc[500:501].to_csv('test500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.iloc[115:116].to_csv('test115.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.iloc[900:901].to_csv('test900.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.iloc[600:601].to_csv('test600.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.iloc[800:801].to_csv('test800.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.iloc[80:81].to_csv('test80.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.iloc[55:56].to_csv('test55.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 410, 1: 508})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res=ros.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 508, 1: 508})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43. ,  0. ,  2. , ...,  1. ,  2. ,  1. ],\n",
       "       [59. ,  0. ,  2. , ...,  0. ,  1. ,  1. ],\n",
       "       [69. ,  0. ,  2. , ...,  0. ,  1. ,  1. ],\n",
       "       ...,\n",
       "       [64. ,  0. ,  2. , ...,  1. ,  1. ,  1. ],\n",
       "       [62. ,  0. ,  1. , ...,  1. ,  1.2,  1. ],\n",
       "       [55. ,  0. ,  0. , ...,  0. ,  0. ,  0. ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X_res, y_res,test_size=0.2)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.linear_model._logistic.LogisticRegression"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=lr.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8260869565217391"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "ac=accuracy_score(y_test,y_pred)\n",
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf=confusion_matrix(y_test,y_pred)\n",
    "cr=classification_report(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61, 15],\n",
       "       [17, 91]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.78      0.80      0.79        76\\n           1       0.86      0.84      0.85       108\\n\\n    accuracy                           0.83       184\\n   macro avg       0.82      0.82      0.82       184\\nweighted avg       0.83      0.83      0.83       184\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc_clf=DecisionTreeClassifier()\n",
    "dtc_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict=dtc_clf.predict(x_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7608695652173914"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ac1=accuracy_score(y_test,y_predict)\n",
    "ac1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf1=confusion_matrix(y_test,y_predict)\n",
    "cr1=classification_report(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61, 15],\n",
       "       [29, 79]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.68      0.80      0.73        76\\n           1       0.84      0.73      0.78       108\\n\\n    accuracy                           0.76       184\\n   macro avg       0.76      0.77      0.76       184\\nweighted avg       0.77      0.76      0.76       184\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lr2.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr,\"lr2.joblib\")+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rmf=RandomForestClassifier(max_depth=3,random_state=0)\n",
    "rmf_clf=rmf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict1=rmf_clf.predict(x_test)\n",
    "y_predict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8478260869565217"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ac1=accuracy_score(y_test,y_predict1)\n",
    "ac1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 736 samples, validate on 82 samples\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/360\n",
      "736/736 [==============================] - 2s 3ms/sample - loss: 0.6800 - acc: 0.5435 - val_loss: 0.6184 - val_acc: 0.5976\n",
      "Epoch 2/360\n",
      "736/736 [==============================] - 1s 729us/sample - loss: 0.6272 - acc: 0.6168 - val_loss: 0.5742 - val_acc: 0.6341\n",
      "Epoch 3/360\n",
      "736/736 [==============================] - 0s 641us/sample - loss: 0.6380 - acc: 0.5897 - val_loss: 0.6043 - val_acc: 0.6585\n",
      "Epoch 4/360\n",
      "736/736 [==============================] - 0s 598us/sample - loss: 0.6376 - acc: 0.5992 - val_loss: 0.5690 - val_acc: 0.6585\n",
      "Epoch 5/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.6403 - acc: 0.6168 - val_loss: 0.5880 - val_acc: 0.6463\n",
      "Epoch 6/360\n",
      "736/736 [==============================] - 0s 597us/sample - loss: 0.6252 - acc: 0.6101 - val_loss: 0.5728 - val_acc: 0.6585\n",
      "Epoch 7/360\n",
      "736/736 [==============================] - 0s 614us/sample - loss: 0.6364 - acc: 0.6114 - val_loss: 0.5845 - val_acc: 0.6707\n",
      "Epoch 8/360\n",
      "736/736 [==============================] - 0s 630us/sample - loss: 0.6209 - acc: 0.6168 - val_loss: 0.5691 - val_acc: 0.6585\n",
      "Epoch 9/360\n",
      "736/736 [==============================] - 0s 620us/sample - loss: 0.6357 - acc: 0.6168 - val_loss: 0.5787 - val_acc: 0.6463\n",
      "Epoch 10/360\n",
      "736/736 [==============================] - 1s 685us/sample - loss: 0.6365 - acc: 0.5883 - val_loss: 0.5825 - val_acc: 0.6585\n",
      "Epoch 11/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.6219 - acc: 0.6277 - val_loss: 0.5800 - val_acc: 0.6585\n",
      "Epoch 12/360\n",
      "736/736 [==============================] - 1s 683us/sample - loss: 0.6192 - acc: 0.6141 - val_loss: 0.5611 - val_acc: 0.6829\n",
      "Epoch 13/360\n",
      "736/736 [==============================] - 1s 709us/sample - loss: 0.6238 - acc: 0.6223 - val_loss: 0.5885 - val_acc: 0.6341\n",
      "Epoch 14/360\n",
      "736/736 [==============================] - 1s 683us/sample - loss: 0.6248 - acc: 0.6155 - val_loss: 0.5707 - val_acc: 0.6707\n",
      "Epoch 15/360\n",
      "736/736 [==============================] - 0s 641us/sample - loss: 0.6300 - acc: 0.6481 - val_loss: 0.5795 - val_acc: 0.6585\n",
      "Epoch 16/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.6153 - acc: 0.6413 - val_loss: 0.5611 - val_acc: 0.6585\n",
      "Epoch 17/360\n",
      "736/736 [==============================] - 0s 661us/sample - loss: 0.6347 - acc: 0.6250 - val_loss: 0.5769 - val_acc: 0.6341\n",
      "Epoch 18/360\n",
      "736/736 [==============================] - 1s 683us/sample - loss: 0.6244 - acc: 0.6141 - val_loss: 0.5662 - val_acc: 0.6585\n",
      "Epoch 19/360\n",
      "736/736 [==============================] - 1s 684us/sample - loss: 0.6150 - acc: 0.6495 - val_loss: 0.5661 - val_acc: 0.6585\n",
      "Epoch 20/360\n",
      "736/736 [==============================] - 0s 640us/sample - loss: 0.6341 - acc: 0.6440 - val_loss: 0.5617 - val_acc: 0.6707\n",
      "Epoch 21/360\n",
      "736/736 [==============================] - 0s 598us/sample - loss: 0.6170 - acc: 0.6427 - val_loss: 0.5599 - val_acc: 0.6707\n",
      "Epoch 22/360\n",
      "736/736 [==============================] - 0s 662us/sample - loss: 0.6299 - acc: 0.6019 - val_loss: 0.5869 - val_acc: 0.6585\n",
      "Epoch 23/360\n",
      "736/736 [==============================] - 1s 726us/sample - loss: 0.6319 - acc: 0.6236 - val_loss: 0.5610 - val_acc: 0.6951\n",
      "Epoch 24/360\n",
      "736/736 [==============================] - 1s 739us/sample - loss: 0.6405 - acc: 0.6277 - val_loss: 0.5646 - val_acc: 0.6829\n",
      "Epoch 25/360\n",
      "736/736 [==============================] - 0s 647us/sample - loss: 0.6199 - acc: 0.6495 - val_loss: 0.5769 - val_acc: 0.6951\n",
      "Epoch 26/360\n",
      "736/736 [==============================] - 1s 714us/sample - loss: 0.6192 - acc: 0.6277 - val_loss: 0.5756 - val_acc: 0.6585\n",
      "Epoch 27/360\n",
      "736/736 [==============================] - 1s 716us/sample - loss: 0.6174 - acc: 0.6345 - val_loss: 0.5523 - val_acc: 0.7073\n",
      "Epoch 28/360\n",
      "736/736 [==============================] - 1s 725us/sample - loss: 0.6172 - acc: 0.6454 - val_loss: 0.5573 - val_acc: 0.7073\n",
      "Epoch 29/360\n",
      "736/736 [==============================] - 1s 736us/sample - loss: 0.6161 - acc: 0.6617 - val_loss: 0.5588 - val_acc: 0.7195\n",
      "Epoch 30/360\n",
      "736/736 [==============================] - 1s 680us/sample - loss: 0.6179 - acc: 0.6427 - val_loss: 0.5553 - val_acc: 0.7317\n",
      "Epoch 31/360\n",
      "736/736 [==============================] - 1s 721us/sample - loss: 0.6129 - acc: 0.6413 - val_loss: 0.5635 - val_acc: 0.6585\n",
      "Epoch 32/360\n",
      "736/736 [==============================] - 1s 703us/sample - loss: 0.6217 - acc: 0.6413 - val_loss: 0.5703 - val_acc: 0.6585\n",
      "Epoch 33/360\n",
      "736/736 [==============================] - 0s 662us/sample - loss: 0.6119 - acc: 0.6603 - val_loss: 0.5609 - val_acc: 0.6585\n",
      "Epoch 34/360\n",
      "736/736 [==============================] - 0s 641us/sample - loss: 0.6117 - acc: 0.6522 - val_loss: 0.5474 - val_acc: 0.7195\n",
      "Epoch 35/360\n",
      "736/736 [==============================] - 0s 640us/sample - loss: 0.6099 - acc: 0.6508 - val_loss: 0.5413 - val_acc: 0.7073\n",
      "Epoch 36/360\n",
      "736/736 [==============================] - 1s 769us/sample - loss: 0.6069 - acc: 0.6549 - val_loss: 0.5737 - val_acc: 0.6707\n",
      "Epoch 37/360\n",
      "736/736 [==============================] - 0s 620us/sample - loss: 0.6061 - acc: 0.6658 - val_loss: 0.5441 - val_acc: 0.7073\n",
      "Epoch 38/360\n",
      "736/736 [==============================] - 1s 794us/sample - loss: 0.6082 - acc: 0.6644 - val_loss: 0.5655 - val_acc: 0.6707\n",
      "Epoch 39/360\n",
      "736/736 [==============================] - 1s 749us/sample - loss: 0.6081 - acc: 0.6413 - val_loss: 0.5415 - val_acc: 0.7317\n",
      "Epoch 40/360\n",
      "736/736 [==============================] - 1s 791us/sample - loss: 0.6137 - acc: 0.6440 - val_loss: 0.5471 - val_acc: 0.6707\n",
      "Epoch 41/360\n",
      "736/736 [==============================] - 1s 708us/sample - loss: 0.6074 - acc: 0.6630 - val_loss: 0.5479 - val_acc: 0.7195\n",
      "Epoch 42/360\n",
      "736/736 [==============================] - 1s 872us/sample - loss: 0.6132 - acc: 0.6318 - val_loss: 0.5534 - val_acc: 0.6707\n",
      "Epoch 43/360\n",
      "736/736 [==============================] - 1s 754us/sample - loss: 0.6111 - acc: 0.6508 - val_loss: 0.5458 - val_acc: 0.7073\n",
      "Epoch 44/360\n",
      "736/736 [==============================] - 1s 817us/sample - loss: 0.6085 - acc: 0.6685 - val_loss: 0.5368 - val_acc: 0.6951\n",
      "Epoch 45/360\n",
      "736/736 [==============================] - 1s 849us/sample - loss: 0.6016 - acc: 0.6698 - val_loss: 0.5597 - val_acc: 0.6951\n",
      "Epoch 46/360\n",
      "736/736 [==============================] - 1s 901us/sample - loss: 0.6078 - acc: 0.6671 - val_loss: 0.5502 - val_acc: 0.6463\n",
      "Epoch 47/360\n",
      "736/736 [==============================] - 1s 821us/sample - loss: 0.6035 - acc: 0.6671 - val_loss: 0.5531 - val_acc: 0.6707\n",
      "Epoch 48/360\n",
      "736/736 [==============================] - 1s 927us/sample - loss: 0.6007 - acc: 0.6644 - val_loss: 0.5304 - val_acc: 0.6951\n",
      "Epoch 49/360\n",
      "736/736 [==============================] - 1s 761us/sample - loss: 0.6079 - acc: 0.6726 - val_loss: 0.5357 - val_acc: 0.6951\n",
      "Epoch 50/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.6158 - acc: 0.6671 - val_loss: 0.5445 - val_acc: 0.7073\n",
      "Epoch 51/360\n",
      "736/736 [==============================] - 0s 663us/sample - loss: 0.6048 - acc: 0.6617 - val_loss: 0.5297 - val_acc: 0.7439\n",
      "Epoch 52/360\n",
      "736/736 [==============================] - 0s 640us/sample - loss: 0.6119 - acc: 0.6603 - val_loss: 0.5461 - val_acc: 0.7561\n",
      "Epoch 53/360\n",
      "736/736 [==============================] - 1s 706us/sample - loss: 0.6148 - acc: 0.6535 - val_loss: 0.5557 - val_acc: 0.7195\n",
      "Epoch 54/360\n",
      "736/736 [==============================] - 1s 689us/sample - loss: 0.5959 - acc: 0.6807 - val_loss: 0.5397 - val_acc: 0.6951\n",
      "Epoch 55/360\n",
      "736/736 [==============================] - 0s 640us/sample - loss: 0.6058 - acc: 0.6712 - val_loss: 0.5295 - val_acc: 0.7317\n",
      "Epoch 56/360\n",
      "736/736 [==============================] - 0s 620us/sample - loss: 0.5951 - acc: 0.6726 - val_loss: 0.5291 - val_acc: 0.7439\n",
      "Epoch 57/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.5957 - acc: 0.6807 - val_loss: 0.5381 - val_acc: 0.7317\n",
      "Epoch 58/360\n",
      "736/736 [==============================] - 0s 642us/sample - loss: 0.5990 - acc: 0.6739 - val_loss: 0.5761 - val_acc: 0.6707\n",
      "Epoch 59/360\n",
      "736/736 [==============================] - 0s 634us/sample - loss: 0.6159 - acc: 0.6332 - val_loss: 0.5538 - val_acc: 0.6829\n",
      "Epoch 60/360\n",
      "736/736 [==============================] - 0s 644us/sample - loss: 0.6126 - acc: 0.6576 - val_loss: 0.5532 - val_acc: 0.7195\n",
      "Epoch 61/360\n",
      "736/736 [==============================] - 0s 611us/sample - loss: 0.6109 - acc: 0.6753 - val_loss: 0.5305 - val_acc: 0.7195\n",
      "Epoch 62/360\n",
      "736/736 [==============================] - 0s 629us/sample - loss: 0.5947 - acc: 0.6753 - val_loss: 0.5112 - val_acc: 0.7317\n",
      "Epoch 63/360\n",
      "736/736 [==============================] - 0s 622us/sample - loss: 0.6134 - acc: 0.6889 - val_loss: 0.5826 - val_acc: 0.6585\n",
      "Epoch 64/360\n",
      "736/736 [==============================] - 0s 621us/sample - loss: 0.6106 - acc: 0.6590 - val_loss: 0.5223 - val_acc: 0.7073\n",
      "Epoch 65/360\n",
      "736/736 [==============================] - 0s 620us/sample - loss: 0.5999 - acc: 0.6590 - val_loss: 0.5327 - val_acc: 0.7195\n",
      "Epoch 66/360\n",
      "736/736 [==============================] - 0s 623us/sample - loss: 0.5955 - acc: 0.6766 - val_loss: 0.5135 - val_acc: 0.7439\n",
      "Epoch 67/360\n",
      "736/736 [==============================] - 0s 605us/sample - loss: 0.6012 - acc: 0.6603 - val_loss: 0.5178 - val_acc: 0.7561\n",
      "Epoch 68/360\n",
      "736/736 [==============================] - 0s 650us/sample - loss: 0.5890 - acc: 0.6807 - val_loss: 0.5374 - val_acc: 0.7073\n",
      "Epoch 69/360\n",
      "736/736 [==============================] - 0s 597us/sample - loss: 0.5888 - acc: 0.6739 - val_loss: 0.5138 - val_acc: 0.7317\n",
      "Epoch 70/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.5937 - acc: 0.6793 - val_loss: 0.5345 - val_acc: 0.7561\n",
      "Epoch 71/360\n",
      "736/736 [==============================] - 0s 621us/sample - loss: 0.5925 - acc: 0.6793 - val_loss: 0.5427 - val_acc: 0.7195\n",
      "Epoch 72/360\n",
      "736/736 [==============================] - 0s 630us/sample - loss: 0.5935 - acc: 0.6739 - val_loss: 0.5119 - val_acc: 0.7317\n",
      "Epoch 73/360\n",
      "736/736 [==============================] - 0s 622us/sample - loss: 0.5971 - acc: 0.6698 - val_loss: 0.5412 - val_acc: 0.7073\n",
      "Epoch 74/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.5877 - acc: 0.6671 - val_loss: 0.5190 - val_acc: 0.7073\n",
      "Epoch 75/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.5845 - acc: 0.6957 - val_loss: 0.5481 - val_acc: 0.7439\n",
      "Epoch 76/360\n",
      "736/736 [==============================] - 0s 617us/sample - loss: 0.5789 - acc: 0.6875 - val_loss: 0.5134 - val_acc: 0.7805\n",
      "Epoch 77/360\n",
      "736/736 [==============================] - 0s 618us/sample - loss: 0.5702 - acc: 0.7120 - val_loss: 0.5223 - val_acc: 0.6341\n",
      "Epoch 78/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.5832 - acc: 0.6753 - val_loss: 0.5050 - val_acc: 0.8171\n",
      "Epoch 79/360\n",
      "736/736 [==============================] - 0s 621us/sample - loss: 0.5599 - acc: 0.7160 - val_loss: 0.4940 - val_acc: 0.7927\n",
      "Epoch 80/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.5658 - acc: 0.7092 - val_loss: 0.4895 - val_acc: 0.7805\n",
      "Epoch 81/360\n",
      "736/736 [==============================] - 0s 609us/sample - loss: 0.5611 - acc: 0.7120 - val_loss: 0.4942 - val_acc: 0.8049\n",
      "Epoch 82/360\n",
      "736/736 [==============================] - 0s 618us/sample - loss: 0.5566 - acc: 0.7296 - val_loss: 0.4729 - val_acc: 0.8049\n",
      "Epoch 83/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.5363 - acc: 0.7160 - val_loss: 0.6065 - val_acc: 0.7073\n",
      "Epoch 84/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.5609 - acc: 0.7228 - val_loss: 0.5253 - val_acc: 0.6829\n",
      "Epoch 85/360\n",
      "736/736 [==============================] - 0s 618us/sample - loss: 0.5537 - acc: 0.7024 - val_loss: 0.4807 - val_acc: 0.7805\n",
      "Epoch 86/360\n",
      "736/736 [==============================] - 0s 611us/sample - loss: 0.5361 - acc: 0.7133 - val_loss: 0.4743 - val_acc: 0.7805\n",
      "Epoch 87/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.5454 - acc: 0.7269 - val_loss: 0.4990 - val_acc: 0.7317\n",
      "Epoch 88/360\n",
      "736/736 [==============================] - 0s 609us/sample - loss: 0.5494 - acc: 0.7337 - val_loss: 0.4800 - val_acc: 0.7683\n",
      "Epoch 89/360\n",
      "736/736 [==============================] - 0s 629us/sample - loss: 0.5244 - acc: 0.7296 - val_loss: 0.4954 - val_acc: 0.7561\n",
      "Epoch 90/360\n",
      "736/736 [==============================] - 0s 620us/sample - loss: 0.5225 - acc: 0.7364 - val_loss: 0.4994 - val_acc: 0.7805\n",
      "Epoch 91/360\n",
      "736/736 [==============================] - 0s 598us/sample - loss: 0.5223 - acc: 0.7323 - val_loss: 0.4718 - val_acc: 0.7927\n",
      "Epoch 92/360\n",
      "736/736 [==============================] - 0s 601us/sample - loss: 0.5363 - acc: 0.7459 - val_loss: 0.4771 - val_acc: 0.7683\n",
      "Epoch 93/360\n",
      "736/736 [==============================] - 0s 625us/sample - loss: 0.5206 - acc: 0.7459 - val_loss: 0.4855 - val_acc: 0.7439\n",
      "Epoch 94/360\n",
      "736/736 [==============================] - 0s 594us/sample - loss: 0.5207 - acc: 0.7323 - val_loss: 0.5470 - val_acc: 0.6951\n",
      "Epoch 95/360\n",
      "736/736 [==============================] - 0s 609us/sample - loss: 0.5361 - acc: 0.7283 - val_loss: 0.4578 - val_acc: 0.7927\n",
      "Epoch 96/360\n",
      "736/736 [==============================] - 0s 618us/sample - loss: 0.5162 - acc: 0.7391 - val_loss: 0.4977 - val_acc: 0.7805\n",
      "Epoch 97/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.5134 - acc: 0.7378 - val_loss: 0.4850 - val_acc: 0.7317\n",
      "Epoch 98/360\n",
      "736/736 [==============================] - 0s 618us/sample - loss: 0.5060 - acc: 0.7446 - val_loss: 0.4774 - val_acc: 0.7805\n",
      "Epoch 99/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.5040 - acc: 0.7568 - val_loss: 0.4695 - val_acc: 0.7561\n",
      "Epoch 100/360\n",
      "736/736 [==============================] - 0s 617us/sample - loss: 0.4834 - acc: 0.7514 - val_loss: 0.4762 - val_acc: 0.7683\n",
      "Epoch 101/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.4888 - acc: 0.7527 - val_loss: 0.4986 - val_acc: 0.7439\n",
      "Epoch 102/360\n",
      "736/736 [==============================] - 0s 608us/sample - loss: 0.4771 - acc: 0.7677 - val_loss: 0.5180 - val_acc: 0.7439\n",
      "Epoch 103/360\n",
      "736/736 [==============================] - 0s 620us/sample - loss: 0.4952 - acc: 0.7595 - val_loss: 0.4648 - val_acc: 0.7683\n",
      "Epoch 104/360\n",
      "736/736 [==============================] - 0s 618us/sample - loss: 0.4812 - acc: 0.7649 - val_loss: 0.5052 - val_acc: 0.7561\n",
      "Epoch 105/360\n",
      "736/736 [==============================] - 0s 598us/sample - loss: 0.4717 - acc: 0.7527 - val_loss: 0.4680 - val_acc: 0.7683\n",
      "Epoch 106/360\n",
      "736/736 [==============================] - 0s 624us/sample - loss: 0.5030 - acc: 0.7636 - val_loss: 0.5662 - val_acc: 0.7073\n",
      "Epoch 107/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.4795 - acc: 0.7677 - val_loss: 0.5078 - val_acc: 0.7073\n",
      "Epoch 108/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.4657 - acc: 0.7758 - val_loss: 0.5551 - val_acc: 0.7195\n",
      "Epoch 109/360\n",
      "736/736 [==============================] - 0s 608us/sample - loss: 0.4564 - acc: 0.7799 - val_loss: 0.5152 - val_acc: 0.7317\n",
      "Epoch 110/360\n",
      "736/736 [==============================] - 0s 631us/sample - loss: 0.4470 - acc: 0.8057 - val_loss: 0.4997 - val_acc: 0.7561\n",
      "Epoch 111/360\n",
      "736/736 [==============================] - 0s 618us/sample - loss: 0.4601 - acc: 0.7812 - val_loss: 0.4736 - val_acc: 0.7683\n",
      "Epoch 112/360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/736 [==============================] - 0s 618us/sample - loss: 0.4476 - acc: 0.7785 - val_loss: 0.6063 - val_acc: 0.6829\n",
      "Epoch 113/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.5062 - acc: 0.7677 - val_loss: 0.4866 - val_acc: 0.7683\n",
      "Epoch 114/360\n",
      "736/736 [==============================] - 0s 599us/sample - loss: 0.4569 - acc: 0.7921 - val_loss: 0.4771 - val_acc: 0.7561\n",
      "Epoch 115/360\n",
      "736/736 [==============================] - 0s 630us/sample - loss: 0.4541 - acc: 0.7948 - val_loss: 0.5282 - val_acc: 0.7317\n",
      "Epoch 116/360\n",
      "736/736 [==============================] - 0s 597us/sample - loss: 0.4382 - acc: 0.7867 - val_loss: 0.5735 - val_acc: 0.7073\n",
      "Epoch 117/360\n",
      "736/736 [==============================] - 0s 609us/sample - loss: 0.4149 - acc: 0.8139 - val_loss: 0.4941 - val_acc: 0.7561\n",
      "Epoch 118/360\n",
      "736/736 [==============================] - 0s 598us/sample - loss: 0.4579 - acc: 0.8084 - val_loss: 0.5015 - val_acc: 0.7561\n",
      "Epoch 119/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.4111 - acc: 0.8139 - val_loss: 0.5321 - val_acc: 0.7073\n",
      "Epoch 120/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.4079 - acc: 0.8071 - val_loss: 0.5919 - val_acc: 0.7073\n",
      "Epoch 121/360\n",
      "736/736 [==============================] - 0s 597us/sample - loss: 0.3868 - acc: 0.8207 - val_loss: 0.5856 - val_acc: 0.6829\n",
      "Epoch 122/360\n",
      "736/736 [==============================] - 0s 604us/sample - loss: 0.4031 - acc: 0.8274 - val_loss: 0.6032 - val_acc: 0.7317\n",
      "Epoch 123/360\n",
      "736/736 [==============================] - 0s 618us/sample - loss: 0.3502 - acc: 0.8628 - val_loss: 0.6651 - val_acc: 0.7195\n",
      "Epoch 124/360\n",
      "736/736 [==============================] - 0s 630us/sample - loss: 0.5672 - acc: 0.7405 - val_loss: 0.5013 - val_acc: 0.7561\n",
      "Epoch 125/360\n",
      "736/736 [==============================] - 0s 608us/sample - loss: 0.4924 - acc: 0.7568 - val_loss: 0.5466 - val_acc: 0.7195\n",
      "Epoch 126/360\n",
      "736/736 [==============================] - 0s 609us/sample - loss: 0.4527 - acc: 0.8057 - val_loss: 0.5502 - val_acc: 0.7317\n",
      "Epoch 127/360\n",
      "736/736 [==============================] - 0s 618us/sample - loss: 0.4533 - acc: 0.7812 - val_loss: 0.5430 - val_acc: 0.7317\n",
      "Epoch 128/360\n",
      "736/736 [==============================] - 0s 598us/sample - loss: 0.4494 - acc: 0.8071 - val_loss: 0.5683 - val_acc: 0.7073\n",
      "Epoch 129/360\n",
      "736/736 [==============================] - 0s 613us/sample - loss: 0.4184 - acc: 0.8166 - val_loss: 0.5364 - val_acc: 0.7195\n",
      "Epoch 130/360\n",
      "736/736 [==============================] - 0s 597us/sample - loss: 0.4107 - acc: 0.8207 - val_loss: 0.6095 - val_acc: 0.7195\n",
      "Epoch 131/360\n",
      "736/736 [==============================] - 0s 621us/sample - loss: 0.4209 - acc: 0.8179 - val_loss: 0.5235 - val_acc: 0.7317\n",
      "Epoch 132/360\n",
      "736/736 [==============================] - 0s 588us/sample - loss: 0.3974 - acc: 0.8111 - val_loss: 0.5673 - val_acc: 0.7073\n",
      "Epoch 133/360\n",
      "736/736 [==============================] - 0s 611us/sample - loss: 0.4311 - acc: 0.7962 - val_loss: 0.6264 - val_acc: 0.7317\n",
      "Epoch 134/360\n",
      "736/736 [==============================] - 0s 617us/sample - loss: 0.3912 - acc: 0.8193 - val_loss: 0.5643 - val_acc: 0.7317\n",
      "Epoch 135/360\n",
      "736/736 [==============================] - 0s 629us/sample - loss: 0.3858 - acc: 0.8410 - val_loss: 0.6860 - val_acc: 0.7317\n",
      "Epoch 136/360\n",
      "736/736 [==============================] - 1s 682us/sample - loss: 0.3782 - acc: 0.8342 - val_loss: 0.6122 - val_acc: 0.7073\n",
      "Epoch 137/360\n",
      "736/736 [==============================] - 0s 624us/sample - loss: 0.3716 - acc: 0.8383 - val_loss: 0.5605 - val_acc: 0.7439\n",
      "Epoch 138/360\n",
      "736/736 [==============================] - 0s 609us/sample - loss: 0.3761 - acc: 0.8356 - val_loss: 0.6479 - val_acc: 0.7073\n",
      "Epoch 139/360\n",
      "736/736 [==============================] - 0s 618us/sample - loss: 0.3888 - acc: 0.8288 - val_loss: 0.6212 - val_acc: 0.7683\n",
      "Epoch 140/360\n",
      "736/736 [==============================] - 0s 607us/sample - loss: 0.3631 - acc: 0.8465 - val_loss: 0.7374 - val_acc: 0.7317\n",
      "Epoch 141/360\n",
      "736/736 [==============================] - 0s 597us/sample - loss: 0.3727 - acc: 0.8492 - val_loss: 0.6677 - val_acc: 0.7317\n",
      "Epoch 142/360\n",
      "736/736 [==============================] - 0s 603us/sample - loss: 0.3509 - acc: 0.8383 - val_loss: 0.5508 - val_acc: 0.7805\n",
      "Epoch 143/360\n",
      "736/736 [==============================] - 0s 617us/sample - loss: 0.3424 - acc: 0.8560 - val_loss: 0.5722 - val_acc: 0.7439\n",
      "Epoch 144/360\n",
      "736/736 [==============================] - 0s 620us/sample - loss: 0.3670 - acc: 0.8533 - val_loss: 0.6054 - val_acc: 0.7561\n",
      "Epoch 145/360\n",
      "736/736 [==============================] - 0s 626us/sample - loss: 0.3280 - acc: 0.8519 - val_loss: 0.5732 - val_acc: 0.7927\n",
      "Epoch 146/360\n",
      "736/736 [==============================] - 0s 610us/sample - loss: 0.3665 - acc: 0.8410 - val_loss: 0.6054 - val_acc: 0.7195\n",
      "Epoch 147/360\n",
      "736/736 [==============================] - 0s 620us/sample - loss: 0.3394 - acc: 0.8492 - val_loss: 0.6952 - val_acc: 0.7317\n",
      "Epoch 148/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.3130 - acc: 0.8560 - val_loss: 0.6813 - val_acc: 0.7439\n",
      "Epoch 149/360\n",
      "736/736 [==============================] - 0s 609us/sample - loss: 0.3102 - acc: 0.8655 - val_loss: 0.6917 - val_acc: 0.7683\n",
      "Epoch 150/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.2994 - acc: 0.8791 - val_loss: 0.6459 - val_acc: 0.7927\n",
      "Epoch 151/360\n",
      "736/736 [==============================] - 0s 597us/sample - loss: 0.3137 - acc: 0.8818 - val_loss: 0.7080 - val_acc: 0.7683\n",
      "Epoch 152/360\n",
      "736/736 [==============================] - 0s 618us/sample - loss: 0.2718 - acc: 0.8859 - val_loss: 0.8575 - val_acc: 0.7683\n",
      "Epoch 153/360\n",
      "736/736 [==============================] - 0s 618us/sample - loss: 0.2918 - acc: 0.8655 - val_loss: 0.5723 - val_acc: 0.8293\n",
      "Epoch 154/360\n",
      "736/736 [==============================] - 0s 618us/sample - loss: 0.2974 - acc: 0.8614 - val_loss: 0.7167 - val_acc: 0.7317\n",
      "Epoch 155/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.3267 - acc: 0.8628 - val_loss: 0.7173 - val_acc: 0.7439\n",
      "Epoch 156/360\n",
      "736/736 [==============================] - 0s 600us/sample - loss: 0.3416 - acc: 0.8560 - val_loss: 0.5975 - val_acc: 0.7561\n",
      "Epoch 157/360\n",
      "736/736 [==============================] - 0s 597us/sample - loss: 0.3716 - acc: 0.8356 - val_loss: 0.5730 - val_acc: 0.7561\n",
      "Epoch 158/360\n",
      "736/736 [==============================] - 0s 600us/sample - loss: 0.3252 - acc: 0.8533 - val_loss: 0.7179 - val_acc: 0.7683\n",
      "Epoch 159/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.3104 - acc: 0.8709 - val_loss: 0.7174 - val_acc: 0.7317\n",
      "Epoch 160/360\n",
      "736/736 [==============================] - 0s 603us/sample - loss: 0.2683 - acc: 0.8818 - val_loss: 0.8434 - val_acc: 0.7317\n",
      "Epoch 161/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.2955 - acc: 0.8682 - val_loss: 0.7144 - val_acc: 0.7805\n",
      "Epoch 162/360\n",
      "736/736 [==============================] - 0s 618us/sample - loss: 0.2552 - acc: 0.8981 - val_loss: 0.6867 - val_acc: 0.7195\n",
      "Epoch 163/360\n",
      "736/736 [==============================] - 0s 619us/sample - loss: 0.2801 - acc: 0.8940 - val_loss: 0.8245 - val_acc: 0.7683\n",
      "Epoch 164/360\n",
      "736/736 [==============================] - 0s 620us/sample - loss: 0.3115 - acc: 0.8736 - val_loss: 0.7175 - val_acc: 0.7683\n",
      "Epoch 165/360\n",
      "736/736 [==============================] - 0s 608us/sample - loss: 0.2665 - acc: 0.9008 - val_loss: 1.0191 - val_acc: 0.7195\n",
      "Epoch 166/360\n",
      "736/736 [==============================] - 0s 616us/sample - loss: 0.2634 - acc: 0.9035 - val_loss: 1.1656 - val_acc: 0.7073\n",
      "Epoch 167/360\n",
      "736/736 [==============================] - 0s 636us/sample - loss: 0.2628 - acc: 0.8954 - val_loss: 0.7380 - val_acc: 0.7439\n",
      "Epoch 168/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.2574 - acc: 0.9144 - val_loss: 0.7597 - val_acc: 0.7439\n",
      "Epoch 169/360\n",
      "736/736 [==============================] - 0s 661us/sample - loss: 0.2529 - acc: 0.8967 - val_loss: 0.9270 - val_acc: 0.7561\n",
      "Epoch 170/360\n",
      "736/736 [==============================] - 1s 685us/sample - loss: 0.2694 - acc: 0.8832 - val_loss: 0.6896 - val_acc: 0.7927\n",
      "Epoch 171/360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/736 [==============================] - 0s 654us/sample - loss: 0.2239 - acc: 0.9049 - val_loss: 0.6916 - val_acc: 0.7439\n",
      "Epoch 172/360\n",
      "736/736 [==============================] - 0s 661us/sample - loss: 0.1837 - acc: 0.9293 - val_loss: 0.8736 - val_acc: 0.7683\n",
      "Epoch 173/360\n",
      "736/736 [==============================] - 0s 673us/sample - loss: 0.1808 - acc: 0.9348 - val_loss: 1.1180 - val_acc: 0.7805\n",
      "Epoch 174/360\n",
      "736/736 [==============================] - 0s 661us/sample - loss: 0.1938 - acc: 0.9266 - val_loss: 1.1557 - val_acc: 0.7561\n",
      "Epoch 175/360\n",
      "736/736 [==============================] - 0s 650us/sample - loss: 0.1671 - acc: 0.9375 - val_loss: 1.2118 - val_acc: 0.7561\n",
      "Epoch 176/360\n",
      "736/736 [==============================] - 0s 640us/sample - loss: 0.1993 - acc: 0.9226 - val_loss: 1.1571 - val_acc: 0.7439\n",
      "Epoch 177/360\n",
      "736/736 [==============================] - 1s 683us/sample - loss: 0.1982 - acc: 0.9198 - val_loss: 1.1031 - val_acc: 0.7439\n",
      "Epoch 178/360\n",
      "736/736 [==============================] - 0s 662us/sample - loss: 0.2034 - acc: 0.9130 - val_loss: 0.9031 - val_acc: 0.7439\n",
      "Epoch 179/360\n",
      "736/736 [==============================] - 0s 662us/sample - loss: 0.2271 - acc: 0.9130 - val_loss: 1.0334 - val_acc: 0.7683\n",
      "Epoch 180/360\n",
      "736/736 [==============================] - 0s 665us/sample - loss: 0.1684 - acc: 0.9307 - val_loss: 1.1824 - val_acc: 0.7561\n",
      "Epoch 181/360\n",
      "736/736 [==============================] - 0s 651us/sample - loss: 0.1395 - acc: 0.9497 - val_loss: 1.2286 - val_acc: 0.7439\n",
      "Epoch 182/360\n",
      "736/736 [==============================] - 0s 674us/sample - loss: 0.1653 - acc: 0.9402 - val_loss: 1.1141 - val_acc: 0.7439\n",
      "Epoch 183/360\n",
      "736/736 [==============================] - 1s 705us/sample - loss: 0.2629 - acc: 0.8886 - val_loss: 0.6883 - val_acc: 0.8049\n",
      "Epoch 184/360\n",
      "736/736 [==============================] - 0s 652us/sample - loss: 0.2159 - acc: 0.9062 - val_loss: 1.1658 - val_acc: 0.7317\n",
      "Epoch 185/360\n",
      "736/736 [==============================] - 0s 662us/sample - loss: 0.1742 - acc: 0.9348 - val_loss: 1.3969 - val_acc: 0.7561\n",
      "Epoch 186/360\n",
      "736/736 [==============================] - 0s 662us/sample - loss: 0.1844 - acc: 0.9144 - val_loss: 1.4556 - val_acc: 0.6829\n",
      "Epoch 187/360\n",
      "736/736 [==============================] - 0s 648us/sample - loss: 0.1782 - acc: 0.9253 - val_loss: 1.1333 - val_acc: 0.7805\n",
      "Epoch 188/360\n",
      "736/736 [==============================] - 0s 664us/sample - loss: 0.1352 - acc: 0.9429 - val_loss: 1.3075 - val_acc: 0.7561\n",
      "Epoch 189/360\n",
      "736/736 [==============================] - 0s 668us/sample - loss: 0.1431 - acc: 0.9552 - val_loss: 1.3967 - val_acc: 0.7805\n",
      "Epoch 190/360\n",
      "736/736 [==============================] - 0s 675us/sample - loss: 0.1934 - acc: 0.9171 - val_loss: 1.1883 - val_acc: 0.7683\n",
      "Epoch 191/360\n",
      "736/736 [==============================] - 0s 640us/sample - loss: 0.1668 - acc: 0.9348 - val_loss: 1.3005 - val_acc: 0.7317\n",
      "Epoch 192/360\n",
      "736/736 [==============================] - 0s 662us/sample - loss: 0.1927 - acc: 0.9226 - val_loss: 1.2026 - val_acc: 0.7439\n",
      "Epoch 193/360\n",
      "736/736 [==============================] - 1s 705us/sample - loss: 0.1748 - acc: 0.9321 - val_loss: 1.3072 - val_acc: 0.7439\n",
      "Epoch 194/360\n",
      "736/736 [==============================] - 1s 705us/sample - loss: 0.1245 - acc: 0.9606 - val_loss: 1.4788 - val_acc: 0.7195\n",
      "Epoch 195/360\n",
      "736/736 [==============================] - 1s 726us/sample - loss: 0.1412 - acc: 0.9565 - val_loss: 1.5635 - val_acc: 0.7805\n",
      "Epoch 196/360\n",
      "736/736 [==============================] - 1s 703us/sample - loss: 0.1170 - acc: 0.9552 - val_loss: 1.4662 - val_acc: 0.7805\n",
      "Epoch 197/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.1274 - acc: 0.9511 - val_loss: 1.5772 - val_acc: 0.7683\n",
      "Epoch 198/360\n",
      "736/736 [==============================] - 1s 747us/sample - loss: 0.1379 - acc: 0.9443 - val_loss: 1.3852 - val_acc: 0.7439\n",
      "Epoch 199/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.1697 - acc: 0.9389 - val_loss: 1.2913 - val_acc: 0.7683\n",
      "Epoch 200/360\n",
      "736/736 [==============================] - 1s 746us/sample - loss: 0.0918 - acc: 0.9688 - val_loss: 1.6204 - val_acc: 0.7805\n",
      "Epoch 201/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.1250 - acc: 0.9457 - val_loss: 1.3586 - val_acc: 0.7805\n",
      "Epoch 202/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.1490 - acc: 0.9470 - val_loss: 1.5840 - val_acc: 0.7561\n",
      "Epoch 203/360\n",
      "736/736 [==============================] - 1s 725us/sample - loss: 0.0868 - acc: 0.9701 - val_loss: 1.7628 - val_acc: 0.7561\n",
      "Epoch 204/360\n",
      "736/736 [==============================] - 1s 725us/sample - loss: 0.0906 - acc: 0.9633 - val_loss: 1.6630 - val_acc: 0.7683\n",
      "Epoch 205/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.1402 - acc: 0.9402 - val_loss: 1.7216 - val_acc: 0.7805\n",
      "Epoch 206/360\n",
      "736/736 [==============================] - 1s 700us/sample - loss: 0.1372 - acc: 0.9565 - val_loss: 1.6245 - val_acc: 0.7195\n",
      "Epoch 207/360\n",
      "736/736 [==============================] - 1s 711us/sample - loss: 0.1809 - acc: 0.9484 - val_loss: 1.5189 - val_acc: 0.7561\n",
      "Epoch 208/360\n",
      "736/736 [==============================] - 1s 725us/sample - loss: 0.1240 - acc: 0.9538 - val_loss: 1.3739 - val_acc: 0.7805\n",
      "Epoch 209/360\n",
      "736/736 [==============================] - 1s 705us/sample - loss: 0.1080 - acc: 0.9484 - val_loss: 1.7308 - val_acc: 0.7439\n",
      "Epoch 210/360\n",
      "736/736 [==============================] - 1s 705us/sample - loss: 0.0637 - acc: 0.9783 - val_loss: 1.4832 - val_acc: 0.8049\n",
      "Epoch 211/360\n",
      "736/736 [==============================] - 1s 716us/sample - loss: 0.1097 - acc: 0.9524 - val_loss: 1.6855 - val_acc: 0.7439\n",
      "Epoch 212/360\n",
      "736/736 [==============================] - 1s 695us/sample - loss: 0.1293 - acc: 0.9497 - val_loss: 1.3408 - val_acc: 0.7805\n",
      "Epoch 213/360\n",
      "736/736 [==============================] - 1s 727us/sample - loss: 0.1197 - acc: 0.9484 - val_loss: 1.5555 - val_acc: 0.7561\n",
      "Epoch 214/360\n",
      "736/736 [==============================] - 1s 730us/sample - loss: 0.0898 - acc: 0.9647 - val_loss: 1.6307 - val_acc: 0.7805\n",
      "Epoch 215/360\n",
      "736/736 [==============================] - 1s 734us/sample - loss: 0.0520 - acc: 0.9810 - val_loss: 1.9462 - val_acc: 0.7683\n",
      "Epoch 216/360\n",
      "736/736 [==============================] - 1s 725us/sample - loss: 0.0798 - acc: 0.9769 - val_loss: 1.6571 - val_acc: 0.7683\n",
      "Epoch 217/360\n",
      "736/736 [==============================] - 1s 726us/sample - loss: 0.0862 - acc: 0.9701 - val_loss: 1.7404 - val_acc: 0.7561\n",
      "Epoch 218/360\n",
      "736/736 [==============================] - 1s 725us/sample - loss: 0.1371 - acc: 0.9484 - val_loss: 1.4931 - val_acc: 0.7805\n",
      "Epoch 219/360\n",
      "736/736 [==============================] - 1s 705us/sample - loss: 0.1237 - acc: 0.9524 - val_loss: 1.8490 - val_acc: 0.7317\n",
      "Epoch 220/360\n",
      "736/736 [==============================] - 1s 747us/sample - loss: 0.0971 - acc: 0.9647 - val_loss: 1.6951 - val_acc: 0.7561\n",
      "Epoch 221/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.1602 - acc: 0.9470 - val_loss: 1.6721 - val_acc: 0.7439\n",
      "Epoch 222/360\n",
      "736/736 [==============================] - 1s 748us/sample - loss: 0.1062 - acc: 0.9633 - val_loss: 1.7549 - val_acc: 0.7683\n",
      "Epoch 223/360\n",
      "736/736 [==============================] - 1s 705us/sample - loss: 0.0857 - acc: 0.9701 - val_loss: 1.8918 - val_acc: 0.7439\n",
      "Epoch 224/360\n",
      "736/736 [==============================] - 1s 750us/sample - loss: 0.0889 - acc: 0.9769 - val_loss: 2.2152 - val_acc: 0.7317\n",
      "Epoch 225/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.1112 - acc: 0.9674 - val_loss: 1.4907 - val_acc: 0.7195\n",
      "Epoch 226/360\n",
      "736/736 [==============================] - 1s 770us/sample - loss: 0.0836 - acc: 0.9688 - val_loss: 1.8077 - val_acc: 0.7317\n",
      "Epoch 227/360\n",
      "736/736 [==============================] - 1s 731us/sample - loss: 0.0912 - acc: 0.9660 - val_loss: 1.7019 - val_acc: 0.7805\n",
      "Epoch 228/360\n",
      "736/736 [==============================] - 1s 701us/sample - loss: 0.0702 - acc: 0.9769 - val_loss: 1.9588 - val_acc: 0.7195\n",
      "Epoch 229/360\n",
      "736/736 [==============================] - 1s 747us/sample - loss: 0.0532 - acc: 0.9796 - val_loss: 1.8947 - val_acc: 0.7927\n",
      "Epoch 230/360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/736 [==============================] - 1s 748us/sample - loss: 0.0508 - acc: 0.9864 - val_loss: 2.1488 - val_acc: 0.7683\n",
      "Epoch 231/360\n",
      "736/736 [==============================] - 1s 703us/sample - loss: 0.0659 - acc: 0.9783 - val_loss: 2.0826 - val_acc: 0.7683\n",
      "Epoch 232/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.0483 - acc: 0.9864 - val_loss: 2.2347 - val_acc: 0.7683\n",
      "Epoch 233/360\n",
      "736/736 [==============================] - 1s 728us/sample - loss: 0.0386 - acc: 0.9905 - val_loss: 2.0549 - val_acc: 0.7561\n",
      "Epoch 234/360\n",
      "736/736 [==============================] - 1s 703us/sample - loss: 0.1707 - acc: 0.9402 - val_loss: 2.0947 - val_acc: 0.7317\n",
      "Epoch 235/360\n",
      "736/736 [==============================] - 1s 693us/sample - loss: 0.1817 - acc: 0.9266 - val_loss: 1.8060 - val_acc: 0.7317\n",
      "Epoch 236/360\n",
      "736/736 [==============================] - 1s 682us/sample - loss: 0.0948 - acc: 0.9633 - val_loss: 1.5855 - val_acc: 0.7439\n",
      "Epoch 237/360\n",
      "736/736 [==============================] - 1s 703us/sample - loss: 0.0699 - acc: 0.9769 - val_loss: 1.8276 - val_acc: 0.7073\n",
      "Epoch 238/360\n",
      "736/736 [==============================] - 1s 714us/sample - loss: 0.0602 - acc: 0.9823 - val_loss: 1.7311 - val_acc: 0.7683\n",
      "Epoch 239/360\n",
      "736/736 [==============================] - 1s 684us/sample - loss: 0.0347 - acc: 0.9891 - val_loss: 2.0560 - val_acc: 0.7439\n",
      "Epoch 240/360\n",
      "736/736 [==============================] - 1s 721us/sample - loss: 0.0367 - acc: 0.9918 - val_loss: 1.8326 - val_acc: 0.7683\n",
      "Epoch 241/360\n",
      "736/736 [==============================] - 1s 686us/sample - loss: 0.0277 - acc: 0.9905 - val_loss: 2.0008 - val_acc: 0.7805\n",
      "Epoch 242/360\n",
      "736/736 [==============================] - 1s 694us/sample - loss: 0.0263 - acc: 0.9932 - val_loss: 2.2945 - val_acc: 0.7561\n",
      "Epoch 243/360\n",
      "736/736 [==============================] - 1s 710us/sample - loss: 0.0634 - acc: 0.9796 - val_loss: 1.7801 - val_acc: 0.7561\n",
      "Epoch 244/360\n",
      "736/736 [==============================] - 0s 673us/sample - loss: 0.0423 - acc: 0.9783 - val_loss: 1.9526 - val_acc: 0.7439\n",
      "Epoch 245/360\n",
      "736/736 [==============================] - 1s 725us/sample - loss: 0.0837 - acc: 0.9715 - val_loss: 1.8369 - val_acc: 0.7805\n",
      "Epoch 246/360\n",
      "736/736 [==============================] - 1s 685us/sample - loss: 0.0777 - acc: 0.9674 - val_loss: 1.9784 - val_acc: 0.6951\n",
      "Epoch 247/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.0854 - acc: 0.9688 - val_loss: 1.6206 - val_acc: 0.7683\n",
      "Epoch 248/360\n",
      "736/736 [==============================] - 1s 711us/sample - loss: 0.0861 - acc: 0.9701 - val_loss: 2.0872 - val_acc: 0.7195\n",
      "Epoch 249/360\n",
      "736/736 [==============================] - 1s 682us/sample - loss: 0.0678 - acc: 0.9783 - val_loss: 1.7610 - val_acc: 0.7805\n",
      "Epoch 250/360\n",
      "736/736 [==============================] - 1s 710us/sample - loss: 0.0514 - acc: 0.9878 - val_loss: 1.9026 - val_acc: 0.7683\n",
      "Epoch 251/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.0229 - acc: 0.9959 - val_loss: 2.0580 - val_acc: 0.7561\n",
      "Epoch 252/360\n",
      "736/736 [==============================] - 1s 730us/sample - loss: 0.0178 - acc: 0.9986 - val_loss: 2.2480 - val_acc: 0.7439\n",
      "Epoch 253/360\n",
      "736/736 [==============================] - 1s 699us/sample - loss: 0.0116 - acc: 0.9959 - val_loss: 2.3026 - val_acc: 0.7439\n",
      "Epoch 254/360\n",
      "736/736 [==============================] - 1s 737us/sample - loss: 0.0095 - acc: 0.9973 - val_loss: 2.5499 - val_acc: 0.7317\n",
      "Epoch 255/360\n",
      "736/736 [==============================] - 1s 705us/sample - loss: 0.0097 - acc: 0.9973 - val_loss: 2.5965 - val_acc: 0.7439\n",
      "Epoch 256/360\n",
      "736/736 [==============================] - 1s 727us/sample - loss: 0.0051 - acc: 0.9986 - val_loss: 2.6798 - val_acc: 0.7439\n",
      "Epoch 257/360\n",
      "736/736 [==============================] - 1s 716us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 2.8092 - val_acc: 0.7561\n",
      "Epoch 258/360\n",
      "736/736 [==============================] - 1s 725us/sample - loss: 0.0159 - acc: 0.9959 - val_loss: 2.5730 - val_acc: 0.7317\n",
      "Epoch 259/360\n",
      "736/736 [==============================] - 1s 703us/sample - loss: 0.1423 - acc: 0.9633 - val_loss: 2.0729 - val_acc: 0.7561\n",
      "Epoch 260/360\n",
      "736/736 [==============================] - 1s 702us/sample - loss: 0.0708 - acc: 0.9810 - val_loss: 1.5841 - val_acc: 0.7683\n",
      "Epoch 261/360\n",
      "736/736 [==============================] - 1s 713us/sample - loss: 0.0437 - acc: 0.9878 - val_loss: 1.9149 - val_acc: 0.7317\n",
      "Epoch 262/360\n",
      "736/736 [==============================] - 1s 725us/sample - loss: 0.0280 - acc: 0.9918 - val_loss: 1.9121 - val_acc: 0.7805\n",
      "Epoch 263/360\n",
      "736/736 [==============================] - 1s 726us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 2.2163 - val_acc: 0.7683\n",
      "Epoch 264/360\n",
      "736/736 [==============================] - 1s 725us/sample - loss: 0.0130 - acc: 0.9973 - val_loss: 2.2456 - val_acc: 0.7805\n",
      "Epoch 265/360\n",
      "736/736 [==============================] - 1s 727us/sample - loss: 0.0152 - acc: 0.9959 - val_loss: 2.3500 - val_acc: 0.7561\n",
      "Epoch 266/360\n",
      "736/736 [==============================] - 1s 703us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 2.4593 - val_acc: 0.7561\n",
      "Epoch 267/360\n",
      "736/736 [==============================] - 1s 725us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 2.4464 - val_acc: 0.7683\n",
      "Epoch 268/360\n",
      "736/736 [==============================] - 1s 730us/sample - loss: 0.0039 - acc: 0.9986 - val_loss: 2.5268 - val_acc: 0.7683\n",
      "Epoch 269/360\n",
      "736/736 [==============================] - 1s 690us/sample - loss: 0.0070 - acc: 0.9973 - val_loss: 2.5324 - val_acc: 0.7927\n",
      "Epoch 270/360\n",
      "736/736 [==============================] - 1s 686us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 2.6087 - val_acc: 0.7683\n",
      "Epoch 271/360\n",
      "736/736 [==============================] - 1s 682us/sample - loss: 0.0074 - acc: 0.9959 - val_loss: 2.6153 - val_acc: 0.7927\n",
      "Epoch 272/360\n",
      "736/736 [==============================] - 0s 664us/sample - loss: 0.0058 - acc: 0.9986 - val_loss: 2.6765 - val_acc: 0.7805\n",
      "Epoch 273/360\n",
      "736/736 [==============================] - 1s 683us/sample - loss: 0.0040 - acc: 0.9986 - val_loss: 2.7279 - val_acc: 0.7683\n",
      "Epoch 274/360\n",
      "736/736 [==============================] - 1s 682us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 2.7516 - val_acc: 0.7805\n",
      "Epoch 275/360\n",
      "736/736 [==============================] - 1s 682us/sample - loss: 0.0034 - acc: 0.9986 - val_loss: 2.7656 - val_acc: 0.7805\n",
      "Epoch 276/360\n",
      "736/736 [==============================] - 0s 661us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 2.7886 - val_acc: 0.7805\n",
      "Epoch 277/360\n",
      "736/736 [==============================] - 0s 661us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 2.7914 - val_acc: 0.7805\n",
      "Epoch 278/360\n",
      "736/736 [==============================] - 1s 683us/sample - loss: 0.0020 - acc: 0.9986 - val_loss: 2.8298 - val_acc: 0.7805\n",
      "Epoch 279/360\n",
      "736/736 [==============================] - 1s 683us/sample - loss: 0.0034 - acc: 0.9986 - val_loss: 2.8232 - val_acc: 0.7805\n",
      "Epoch 280/360\n",
      "736/736 [==============================] - 1s 722us/sample - loss: 0.0040 - acc: 0.9959 - val_loss: 2.8608 - val_acc: 0.7805\n",
      "Epoch 281/360\n",
      "736/736 [==============================] - 1s 680us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 2.9131 - val_acc: 0.7805\n",
      "Epoch 282/360\n",
      "736/736 [==============================] - 1s 681us/sample - loss: 0.0065 - acc: 0.9973 - val_loss: 3.0609 - val_acc: 0.7561\n",
      "Epoch 283/360\n",
      "736/736 [==============================] - 1s 681us/sample - loss: 0.0033 - acc: 0.9986 - val_loss: 3.0732 - val_acc: 0.7561\n",
      "Epoch 284/360\n",
      "736/736 [==============================] - 0s 665us/sample - loss: 0.0047 - acc: 0.9986 - val_loss: 3.0251 - val_acc: 0.7561\n",
      "Epoch 285/360\n",
      "736/736 [==============================] - 1s 682us/sample - loss: 0.0058 - acc: 0.9986 - val_loss: 2.9746 - val_acc: 0.7805\n",
      "Epoch 286/360\n",
      "736/736 [==============================] - 1s 683us/sample - loss: 0.0045 - acc: 0.9986 - val_loss: 2.9963 - val_acc: 0.7683\n",
      "Epoch 287/360\n",
      "736/736 [==============================] - 0s 671us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 3.0351 - val_acc: 0.7805\n",
      "Epoch 288/360\n",
      "736/736 [==============================] - 0s 664us/sample - loss: 0.0032 - acc: 1.0000 - val_loss: 3.0948 - val_acc: 0.7561\n",
      "Epoch 289/360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/736 [==============================] - 0s 662us/sample - loss: 0.0027 - acc: 0.9986 - val_loss: 3.1569 - val_acc: 0.7561\n",
      "Epoch 290/360\n",
      "736/736 [==============================] - 0s 661us/sample - loss: 0.0025 - acc: 0.9986 - val_loss: 3.1414 - val_acc: 0.7683\n",
      "Epoch 291/360\n",
      "736/736 [==============================] - 0s 662us/sample - loss: 0.0051 - acc: 0.9959 - val_loss: 3.1153 - val_acc: 0.7683\n",
      "Epoch 292/360\n",
      "736/736 [==============================] - 0s 661us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 3.0987 - val_acc: 0.7683\n",
      "Epoch 293/360\n",
      "736/736 [==============================] - 0s 661us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 2.9787 - val_acc: 0.7805\n",
      "Epoch 294/360\n",
      "736/736 [==============================] - 0s 663us/sample - loss: 0.0041 - acc: 0.9986 - val_loss: 2.9575 - val_acc: 0.7805\n",
      "Epoch 295/360\n",
      "736/736 [==============================] - 0s 661us/sample - loss: 9.1121e-04 - acc: 1.0000 - val_loss: 2.8617 - val_acc: 0.7927\n",
      "Epoch 296/360\n",
      "736/736 [==============================] - 0s 661us/sample - loss: 0.0034 - acc: 0.9973 - val_loss: 2.8325 - val_acc: 0.7805\n",
      "Epoch 297/360\n",
      "736/736 [==============================] - 0s 640us/sample - loss: 0.0042 - acc: 0.9986 - val_loss: 2.9380 - val_acc: 0.7561\n",
      "Epoch 298/360\n",
      "736/736 [==============================] - 0s 646us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 3.1299 - val_acc: 0.7317\n",
      "Epoch 299/360\n",
      "736/736 [==============================] - 0s 662us/sample - loss: 0.0028 - acc: 0.9986 - val_loss: 3.1780 - val_acc: 0.7439\n",
      "Epoch 300/360\n",
      "736/736 [==============================] - 0s 664us/sample - loss: 0.0330 - acc: 0.9932 - val_loss: 2.2567 - val_acc: 0.7927\n",
      "Epoch 301/360\n",
      "736/736 [==============================] - 1s 683us/sample - loss: 0.4988 - acc: 0.8886 - val_loss: 0.9091 - val_acc: 0.7805\n",
      "Epoch 302/360\n",
      "736/736 [==============================] - 0s 640us/sample - loss: 0.3320 - acc: 0.8723 - val_loss: 0.8839 - val_acc: 0.7195\n",
      "Epoch 303/360\n",
      "736/736 [==============================] - 1s 683us/sample - loss: 0.2444 - acc: 0.9035 - val_loss: 0.9105 - val_acc: 0.7195\n",
      "Epoch 304/360\n",
      "736/736 [==============================] - 0s 651us/sample - loss: 0.1965 - acc: 0.9226 - val_loss: 1.1622 - val_acc: 0.7317\n",
      "Epoch 305/360\n",
      "736/736 [==============================] - 1s 681us/sample - loss: 0.1040 - acc: 0.9647 - val_loss: 1.4304 - val_acc: 0.7439\n",
      "Epoch 306/360\n",
      "736/736 [==============================] - 0s 640us/sample - loss: 0.0719 - acc: 0.9783 - val_loss: 1.9896 - val_acc: 0.7195\n",
      "Epoch 307/360\n",
      "736/736 [==============================] - 0s 661us/sample - loss: 0.0430 - acc: 0.9851 - val_loss: 1.9815 - val_acc: 0.7439\n",
      "Epoch 308/360\n",
      "736/736 [==============================] - 1s 692us/sample - loss: 0.0350 - acc: 0.9891 - val_loss: 2.1200 - val_acc: 0.6829\n",
      "Epoch 309/360\n",
      "736/736 [==============================] - 0s 640us/sample - loss: 0.0746 - acc: 0.9769 - val_loss: 1.7719 - val_acc: 0.7683\n",
      "Epoch 310/360\n",
      "736/736 [==============================] - 1s 683us/sample - loss: 0.0728 - acc: 0.9810 - val_loss: 2.0961 - val_acc: 0.6951\n",
      "Epoch 311/360\n",
      "736/736 [==============================] - 1s 703us/sample - loss: 0.0464 - acc: 0.9851 - val_loss: 2.2344 - val_acc: 0.7195\n",
      "Epoch 312/360\n",
      "736/736 [==============================] - 1s 694us/sample - loss: 0.0456 - acc: 0.9891 - val_loss: 2.0948 - val_acc: 0.7439\n",
      "Epoch 313/360\n",
      "736/736 [==============================] - 1s 683us/sample - loss: 0.0528 - acc: 0.9891 - val_loss: 2.2263 - val_acc: 0.6707\n",
      "Epoch 314/360\n",
      "736/736 [==============================] - 1s 683us/sample - loss: 0.0846 - acc: 0.9701 - val_loss: 2.0139 - val_acc: 0.7195\n",
      "Epoch 315/360\n",
      "736/736 [==============================] - 1s 683us/sample - loss: 0.0915 - acc: 0.9674 - val_loss: 2.0931 - val_acc: 0.7317\n",
      "Epoch 316/360\n",
      "736/736 [==============================] - 1s 682us/sample - loss: 0.1160 - acc: 0.9688 - val_loss: 2.0703 - val_acc: 0.7317\n",
      "Epoch 317/360\n",
      "736/736 [==============================] - 1s 710us/sample - loss: 0.0586 - acc: 0.9810 - val_loss: 1.8371 - val_acc: 0.7805\n",
      "Epoch 318/360\n",
      "736/736 [==============================] - 0s 656us/sample - loss: 0.0214 - acc: 0.9946 - val_loss: 2.0400 - val_acc: 0.7439\n",
      "Epoch 319/360\n",
      "736/736 [==============================] - 1s 683us/sample - loss: 0.0170 - acc: 0.9973 - val_loss: 2.1881 - val_acc: 0.7439\n",
      "Epoch 320/360\n",
      "736/736 [==============================] - 0s 672us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 2.3299 - val_acc: 0.7561\n",
      "Epoch 321/360\n",
      "736/736 [==============================] - 0s 661us/sample - loss: 0.0071 - acc: 0.9986 - val_loss: 2.4183 - val_acc: 0.7439\n",
      "Epoch 322/360\n",
      "736/736 [==============================] - 0s 662us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 2.4500 - val_acc: 0.7439\n",
      "Epoch 323/360\n",
      "736/736 [==============================] - 0s 677us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 2.5117 - val_acc: 0.7683\n",
      "Epoch 324/360\n",
      "736/736 [==============================] - 1s 697us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 2.5725 - val_acc: 0.7561\n",
      "Epoch 325/360\n",
      "736/736 [==============================] - 0s 668us/sample - loss: 0.0044 - acc: 0.9986 - val_loss: 2.6256 - val_acc: 0.7439\n",
      "Epoch 326/360\n",
      "736/736 [==============================] - 1s 682us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 2.6699 - val_acc: 0.7561\n",
      "Epoch 327/360\n",
      "736/736 [==============================] - 1s 713us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 2.6790 - val_acc: 0.7439\n",
      "Epoch 328/360\n",
      "736/736 [==============================] - 0s 652us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 2.6786 - val_acc: 0.7439\n",
      "Epoch 329/360\n",
      "736/736 [==============================] - 1s 708us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 2.7285 - val_acc: 0.7561\n",
      "Epoch 330/360\n",
      "736/736 [==============================] - 1s 680us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 2.8270 - val_acc: 0.7439\n",
      "Epoch 331/360\n",
      "736/736 [==============================] - 1s 681us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 2.8481 - val_acc: 0.7561\n",
      "Epoch 332/360\n",
      "736/736 [==============================] - 1s 705us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 2.8639 - val_acc: 0.7683\n",
      "Epoch 333/360\n",
      "736/736 [==============================] - 1s 706us/sample - loss: 0.0033 - acc: 0.9986 - val_loss: 2.8710 - val_acc: 0.7683\n",
      "Epoch 334/360\n",
      "736/736 [==============================] - 1s 693us/sample - loss: 0.0044 - acc: 0.9973 - val_loss: 2.9523 - val_acc: 0.7439\n",
      "Epoch 335/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 2.9873 - val_acc: 0.7561\n",
      "Epoch 336/360\n",
      "736/736 [==============================] - 1s 707us/sample - loss: 0.0036 - acc: 0.9973 - val_loss: 2.9906 - val_acc: 0.7561\n",
      "Epoch 337/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.0059 - acc: 0.9959 - val_loss: 3.0182 - val_acc: 0.7561\n",
      "Epoch 338/360\n",
      "736/736 [==============================] - 1s 682us/sample - loss: 0.0039 - acc: 0.9959 - val_loss: 3.0481 - val_acc: 0.7683\n",
      "Epoch 339/360\n",
      "736/736 [==============================] - 1s 704us/sample - loss: 0.0030 - acc: 0.9986 - val_loss: 3.0217 - val_acc: 0.7439\n",
      "Epoch 340/360\n",
      "736/736 [==============================] - 1s 706us/sample - loss: 0.0026 - acc: 0.9986 - val_loss: 2.9935 - val_acc: 0.7439\n",
      "Epoch 341/360\n",
      "736/736 [==============================] - 1s 725us/sample - loss: 0.0040 - acc: 0.9959 - val_loss: 3.0740 - val_acc: 0.7561\n",
      "Epoch 342/360\n",
      "736/736 [==============================] - 1s 747us/sample - loss: 0.0046 - acc: 0.9973 - val_loss: 3.1093 - val_acc: 0.7561\n",
      "Epoch 343/360\n",
      "736/736 [==============================] - 1s 790us/sample - loss: 0.0046 - acc: 0.9959 - val_loss: 3.1223 - val_acc: 0.7561\n",
      "Epoch 344/360\n",
      "736/736 [==============================] - 1s 725us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 3.1902 - val_acc: 0.7439\n",
      "Epoch 345/360\n",
      "736/736 [==============================] - 1s 920us/sample - loss: 0.0027 - acc: 0.9986 - val_loss: 3.2944 - val_acc: 0.7439\n",
      "Epoch 346/360\n",
      "736/736 [==============================] - 1s 1ms/sample - loss: 0.0025 - acc: 0.9986 - val_loss: 3.2582 - val_acc: 0.7561\n",
      "Epoch 347/360\n",
      "736/736 [==============================] - 1s 1ms/sample - loss: 0.0016 - acc: 0.9986 - val_loss: 3.2292 - val_acc: 0.7561\n",
      "Epoch 348/360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/736 [==============================] - 1s 685us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 3.1798 - val_acc: 0.7561\n",
      "Epoch 349/360\n",
      "736/736 [==============================] - 1s 832us/sample - loss: 0.2545 - acc: 0.9688 - val_loss: 3.0108 - val_acc: 0.6707\n",
      "Epoch 350/360\n",
      "736/736 [==============================] - 1s 834us/sample - loss: 0.4075 - acc: 0.8641 - val_loss: 1.0023 - val_acc: 0.7073\n",
      "Epoch 351/360\n",
      "736/736 [==============================] - 1s 728us/sample - loss: 0.2792 - acc: 0.8736 - val_loss: 1.2963 - val_acc: 0.7073\n",
      "Epoch 352/360\n",
      "736/736 [==============================] - 1s 876us/sample - loss: 0.1556 - acc: 0.9375 - val_loss: 1.3054 - val_acc: 0.7195\n",
      "Epoch 353/360\n",
      "736/736 [==============================] - 1s 725us/sample - loss: 0.0892 - acc: 0.9755 - val_loss: 1.9879 - val_acc: 0.7073\n",
      "Epoch 354/360\n",
      "736/736 [==============================] - 1s 950us/sample - loss: 0.0551 - acc: 0.9837 - val_loss: 1.9006 - val_acc: 0.7073\n",
      "Epoch 355/360\n",
      "736/736 [==============================] - 1s 724us/sample - loss: 0.0258 - acc: 0.9973 - val_loss: 2.2431 - val_acc: 0.7073\n",
      "Epoch 356/360\n",
      "736/736 [==============================] - 1s 1ms/sample - loss: 0.0311 - acc: 0.9973 - val_loss: 2.2536 - val_acc: 0.7439\n",
      "Epoch 357/360\n",
      "736/736 [==============================] - 1s 1ms/sample - loss: 0.0494 - acc: 0.9837 - val_loss: 1.8238 - val_acc: 0.7805\n",
      "Epoch 358/360\n",
      "736/736 [==============================] - 1s 1ms/sample - loss: 0.0643 - acc: 0.9769 - val_loss: 1.8485 - val_acc: 0.7805\n",
      "Epoch 359/360\n",
      "736/736 [==============================] - 1s 1ms/sample - loss: 0.0516 - acc: 0.9810 - val_loss: 2.0093 - val_acc: 0.7439\n",
      "Epoch 360/360\n",
      "736/736 [==============================] - 1s 963us/sample - loss: 0.0259 - acc: 0.9905 - val_loss: 2.2218 - val_acc: 0.7317\n",
      "91/91 [==============================] - 0s 358us/sample - loss: 3.5817 - acc: 0.6593\n",
      "Loss: 3.5816608785272956\n",
      "Accuracy: 0.6593407\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "x_normalized = (x - x.mean()) / x.std()\n",
    "\n",
    "time_steps = 10\n",
    "num_features = x_normalized.shape[1]\n",
    "\n",
    "num_samples = x_normalized.shape[0] - time_steps + 1\n",
    "x_reshaped = np.array([x_normalized[i:i+time_steps] for i in range(num_samples)])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = onehot_encoder.fit_transform(y_encoded.reshape(-1, 1))\n",
    "y_reshaped = y_onehot[time_steps - 1:]\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_reshaped, y_reshaped, test_size=0.1, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(time_steps, num_features), return_sequences=True, activation='relu'),\n",
    "    LSTM(64, return_sequences=True, activation='relu'),\n",
    "    LSTM(32, activation='relu'),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),  \n",
    "    Dense(ytrain.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(xtrain, ytrain, epochs=360, batch_size=32, validation_split=0.1)\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(xtest, ytest)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
